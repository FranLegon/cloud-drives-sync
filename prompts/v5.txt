#### **1. Project Overview & Persona**

You are an expert Go developer specializing in building robust, command-line tools that interact with cloud storage APIs.

Your task is to generate the code for a Go binary named `cloud-drives-sync`. This tool will manage and synchronize files across a user's multiple Google Drive and OneDrive accounts. The primary goals are to de-duplicate files, ensure data is mirrored across providers, and balance storage usage.

#### **2. Core Operational Constraint: The "Sync Folder"**

**This is the most important rule:** The application must **only** interact with files and folders contained within a specific root folder named `synched-cloud-drives` in each account.

*   **Isolation:** The tool must never read, list, modify, or delete any file or folder outside of the `synched-cloud-drives` directory.
*   **Pre-flight Check:** Before executing any command that interacts with the cloud, the tool must perform a "pre-flight check" on all relevant accounts. This check verifies that exactly one folder named `synched-cloud-drives` exists in the root of the drive. If zero or more than one are found, the program must abort with a clear error message instructing the user to resolve the ambiguity manually.

#### **3. Architecture & Design Principles**

*   **Modularity:** Structure the code into logical packages (e.g., `cmd`, `google`, `microsoft`, `database`, `crypto`). All database and cloud provider interactions should be implemented behind interfaces to allow for future extensions (e.g., adding Dropbox support or swapping SQLite for PostgreSQL).
*   **Configuration Management:** All configuration data (API credentials, user tokens, database settings) will be stored in a single `config.json.enc` file in the same directory as the binary.
*   **Security:**
    *   The `config.json.enc` file will be encrypted using AES-256 GCM.
    *   **Do not hardcode the encryption key in the binary.** On first run (`init`), prompt the user to create a master password. This password will be used to derive the encryption key using a key derivation function like Argon2id. The binary will require this password every time it is executed to decrypt the configuration.
*   **API Interaction:**
    *   Use streaming for all file uploads and downloads to minimize memory consumption.
    *   Implement exponential backoff and retry mechanisms for all API calls to handle transient network errors and rate limiting gracefully. Log these events to standard output.
*   **Database:**
    *   Use SQLite for the local metadata database, located at `metadata.db`.
    *   All database operations must be performed through a `Database` interface.

#### **4. Configuration & Database Schema**

*`config.json` (before encryption):*
```json
{
  "google_client": {
    "id": "YOUR_GCP_CLIENT_ID",
    "secret": "YOUR_GCP_CLIENT_SECRET"
  },
  "microsoft_client": {
    "id": "YOUR_AZURE_CLIENT_ID",
    "secret": "YOUR_AZURE_CLIENT_SECRET"
  },
  "users": [
    {
      "provider": "Google",
      "email": "main.user@gmail.com",
      "is_main": true,
      "refresh_token": "..."
    },
    {
      "provider": "Google",
      "email": "backup1@gmail.com",
      "is_main": false,
      "refresh_token": "..."
    },
    {
      "provider": "Microsoft",
      "email": "main.user@outlook.com",
      "is_main": true,
      "refresh_token": "..."
    }
  ]
}
```

*SQLite `files` Table Schema:*
*   `FileID` (TEXT): The internal ID from Google Drive or OneDrive.
*   `Provider` (TEXT): "Google" or "Microsoft".
*   `OwnerEmail` (TEXT): The email of the account that owns the file.
*   `FileHash` (TEXT): SHA-256 hash of the file content.
*   `FileName` (TEXT)
*   `FileSize` (INTEGER)
*   `FileExtension` (TEXT)
*   `ParentFolderID` (TEXT)
*   `ParentFolderName` (TEXT)
*   `CreatedOn` (DATETIME)
*   `LastModified` (DATETIME)
*   `LastSynced` (DATETIME): Timestamp of the last time this record was updated from the cloud.
*   `PRIMARY KEY` (`FileID`, `Provider`): A compound key ensuring that an ID is only unique within the context of its provider.

---

#### **5. Detailed Functionality (Command-Line Flags)**

The binary will execute different functions based on flags. If no flags are provided, it should default to `help`.

*   **`init`**
    *   If `config.json.enc` does not exist, prompt the user to create a master password.
    *   Prompt for the GCP and Azure client credentials and create the initial `config.json` file.
    *   Encrypt the file to `config.json.enc` and exit.
    *   If `metadata.db` does not exist, create it and the `files` table.
    *   If run subsequently, this command can be used to add the initial "main" accounts if they are not yet configured.
    *   Crucially, after the user has added the "main" account for each provider, this command will create the `synched-cloud-drives` folder in the root of that main account's drive if it doesn't already exist.

*   **`add-account`**
    *   Prompts the user to choose "Google" or "Microsoft".
    *   It must first check if a "main" account for the chosen provider already exists in the config. If not, it should instruct the user to add the main account first and exit.
    *   Starts a local web server on `http://localhost:8080` to handle the OAuth 2.0 redirect.
    *   Prints the authorization URL to the console for the user to visit.
    *   After user authorization, captures the authorization code, exchanges it for a refresh token, and adds a new user entry to the `config.json` file as a non-main account before re-encrypting it.
    *   After adding the account, it automatically triggers a sharing operation: the "main" account for that provider shares its `synched-cloud-drives` folder with the newly added backup account, granting "editor" permissions.

*   **`get-metadata`**
    *   After passing the pre-flight check, for each account, recursively scan all files and folders **within the `synched-cloud-drives` folder.**
    *   For each file, calculate its SHA-256 hash.
    *   In the SQLite DB, `INSERT` new file records or `UPDATE` existing ones based on `FileID`. Update the `LastSynced` timestamp.

*   **`check-for-duplicates`**
    *   First, performs the `get-metadata` action to ensure the local DB is up-to-date.
    *   Then, queries the DB to find records with identical `FileHash` values within the same provider.
    *   Prints a list of duplicate files grouped by hash, showing file name, owner, and creation date for each copy.

*   **`remove-duplicates`**
    *   Performs the `check-for-duplicates` action.
    *   For each set of duplicates, prompts the user to select which file(s) to delete. Waits for confirmation before deleting. All actions are confined to the `synched-cloud-drives` folder.

*   **`remove-duplicates-unsafe`**
    *   Performs the `check-for-duplicates` action.
    *   For each set of duplicates, it automatically deletes all copies except the one with the oldest `CreatedOn` date. All actions are confined to the `synched-cloud-drives` folder.

*   **`share-with-main`**
    *   This flag can be used as a utility to "repair" permissions.
    *   After passing the pre-flight check, it verifies that all non-main accounts have editor access to the main account's `synched-cloud-drives` folder and re-applies the permission if missing.

*   **`sync-providers`**
    *   Ensures the metadata is current by running the `get-metadata` logic first.
    *   **Goal:** Make the file content within the `synched-cloud-drives` folder identical across the main Google and Microsoft accounts.
    *   **Logic:**
        1.  Compare the set of file hashes from all Google accounts against the set from all Microsoft accounts.
        2.  If a hash exists in Google but not Microsoft, upload that file to the primary Microsoft Drive.
        3.  If a hash exists in Microsoft but not Google, upload that file to the primary Google Drive.
        4.  The folder structure within `synched-cloud-drives` should be replicated. If a file is at `google-main:/synched-cloud-drives/Work/Reports/Q1.pdf`, it should be created at `microsoft-main:/synched-cloud-drives/Work/Reports/Q1.pdf`.
        5.  *Conflict Handling:* If a file with the same name and path but a different hash exists in the destination, rename the new file being copied (e.g., `Q1_conflict_2025-07-28.pdf`) and proceed with the upload. Log this action clearly.

*   **`balance-storage`**
    *   After passing the pre-flight check, checks the storage quota for every account.
    *   If any single account is over 95% full, it identifies the largest files in that account's `synched-cloud-drives` folder that are not present in any other account (of the same provider).
    *   It then moves these files, one by one, to the backup account of the same provider with the most available free space until the source account is below the 90% threshold.
    *   Ownership of the file is transferred. Update the `OwnerEmail` in the database accordingly.

*   **`free-main`**
    *   All files in `synched-cloud-drives` owned by main account are tranfered to some backup account.
    *   To choose where to transfer each file, choose the backup account with the most free space.
    *   Throw an error if not enough space is available in backup accounts.
    *   Stream download and reupload files with all of their metadata. If you try to use special methods like Google Drive's "transferOwnership", make sure to have basic download/upload as a fallback.

*   **`check-tokens`**
    *   Iterates through all refresh tokens in the config.
    *   For each token, it attempts a simple, read-only API call (like "get user info").
    *   If a token fails with an authentication error, it informs the user which account needs to be re-authenticated and suggests running `add-account` again for that email.

*   **`safe`**
    *   A modifier flag that can be used with other flags (e.g., `cloud-drives-sync remove-duplicates-unsafe --safe`).
    *   When active, no write, delete, or permission-change operations are sent to the cloud providers.
    *   Instead, the tool should print a detailed log of what actions *would* have been taken. Example: `[DRY RUN] DELETE GDrive file 'duplicate.txt' (FileID: xyz) from account 'backup@gmail.com'`.
    *   Read-only operations (listing files, checking quotas) and local DB modifications are still allowed.

*   **`help`**
    *   Lists all available flags, their purpose, and example usage.

#### **6. Expected Response**
Give me all code for the project. Do not use any placeholders.